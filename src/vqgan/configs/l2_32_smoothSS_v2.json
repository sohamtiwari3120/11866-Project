{
  "pipeline": "er2er",
  "tag": "l2_32_smoothSS_style_transfer_lr10_bs32_orig_loss_",
  "who": "listener",
  "segment_tag": "",
  "learning_rate": 10,
  "warmup_steps": 1,
  "model_path": "models/",
  "num_epochs": 5000000,
  "batch_size": 32,
  "log_step": 100,
  "data": {
   "local": true,
   "basedir": "../",
   "speaker": "conan",
   "train_transcript_embeddings_dir": "../data/train_seg_transcripts_embs/",
   "test_transcript_embeddings_dir": "../data/test_seg_transcripts_embs/",
   "less_expressive_style_embeddings_dir": "../data/reference_style_embedidngs/results_less4/code/",
   "more_expressive_style_embeddings_dir": "../data/reference_style_embedidngs/results_more4/code/",
   "transcript_embeddings_dim": 384,
   "transcripts_segmented": true,
   "train_split_ratio": 0.70
  },
  "transformer_config":{
    "in_dim": 56,
    "hidden_size": 256,
    "num_hidden_layers": 12,
    "num_attention_heads": 8,
    "intermediate_size": 384,
    "quant_sequence_length": 4,
    "sequence_length": 32,
    "quant_factor": 3
  },
  "VQuantizer": {
    "n_embed": 200,
    "zquant_dim": 256,
    "style_transfer": true,
    "freeze_codebook": true
  },
  "style_transfer": {
    "loss": {
      "beta_style_transfer": 0.3
    }
  }
}
